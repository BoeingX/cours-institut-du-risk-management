{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_analysis_exercise.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvyPOKPFfZTf",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis\n",
        "\n",
        "Dans ce TP, on va créer et entraîner un réseau de neuronnes récurrent pour l'analyse de sentiment. \n",
        "\n",
        "Le jeu de données que l'on utilise est *IMDB Movie Reviews* où on trouve des revues de films avec chacune sa *polarité* (positif/negatif).\n",
        "\n",
        "Le TP est composé comme suit\n",
        "\n",
        "1.   Chargement et visualisation des données\n",
        "2.   Conception de réseau\n",
        "3.   Entraînement de réseau\n",
        "4.   Validation de réseau\n",
        "\n",
        "Pour gagner du temps, on vous fournit un squelette de code. Les codes ne sont pas complets, et il vous sera demandé de les compléter certains endroits pour qu'ils fonctionnent.\n",
        "\n",
        "Lorsque un bout de code est à compléter, il sera marqué comme ceci\n",
        "```python\n",
        "def factorial(n):\n",
        "  if n == 0:\n",
        "    return 1\n",
        "  ### VOTRE CODE COMMENCE ICI ###\n",
        "  ### VOTRE CODE TERMINE ICI  ###\n",
        "\n",
        "assert factorial(5) == 120\n",
        "```\n",
        "où `assert factorial(5) == 120` sert à tester votre code.\n",
        "\n",
        "Vous devriez le compléter comme ceci\n",
        "```python\n",
        "def factorial(n):\n",
        "  if n == 0:\n",
        "    return 1\n",
        "  ### VOTRE CODE COMMENCE ICI ###\n",
        "  return n * factorial(n - 1)\n",
        "  ### VOTRE CODE TERMINE ICI  ###\n",
        "```\n",
        "\n",
        "\n",
        "Vous n'êtes **pas** obligé de maîtriser les autres codes.\n",
        "\n",
        "Enfin, il est recommendé de compléter le TP dans cet ordre. Toutefois, si vous sentir bloqué, n'hésitez pas à nous soliciter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVtTaOIpj30a",
        "colab_type": "text"
      },
      "source": [
        "On commence par importer des librairies dont on aura besoin par la suite. Vous pouvez aussi importer d'autres librairies de vos choix.\n",
        "\n",
        "Pas de panique si vous n'êtes pas familier avec tous les imports, on vous expliquera plus tard dans le TP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhVkzzC1y3L5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "from glob import iglob\n",
        "from collections import defaultdict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VJuy_RnjwJR",
        "colab_type": "text"
      },
      "source": [
        "## 1. Chargement et visualisation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDZNVl0WlFMt",
        "colab_type": "text"
      },
      "source": [
        "Le jeu de données *IMDB Movie reviews* est composé de 50000 revues de film issues du site IMDB avec chacune sa polarité (i.e. sentiment positif ou sentiment négatif).\n",
        "\n",
        "Il est séparé en deux sous-ensemble de données : \n",
        "\n",
        "*   train: 25000 exemples de données d'entraînement, qui nous servent à **entraîner** les modèles\n",
        "*   test: 25000 exemples de données de teste, qui seront utilisé pour **évaluer** les modèles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDR7nl05nl7j",
        "colab_type": "text"
      },
      "source": [
        "On télécharge d'abord les données brutes (ce qui prendra une dizaine de secondes) avant de les extraire dans un dossier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPdGGSrsnnZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz && tar xf aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDBp8JHZoKbO",
        "colab_type": "text"
      },
      "source": [
        "Voici un exemple d'une revue positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trNrBFmkn5A1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cat aclImdb/train/pos/0_9.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQAmSW-sobWN",
        "colab_type": "text"
      },
      "source": [
        "et voici un exemple d'une revue négative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uXxnXRpoeRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cat aclImdb/train/neg/0_3.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66zW7qU9bwRp",
        "colab_type": "text"
      },
      "source": [
        "On vous fournit une fonction pour charger les données d'entraînement et celles de test en mémoire.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSJZnddiNUB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(path, shuffle=True, seed=42):\n",
        "  def load(train_or_test):\n",
        "    data = []\n",
        "    for polarity in ['pos', 'neg']:\n",
        "      for filename in iglob(os.path.join(path, train_or_test, polarity, '*.txt')):\n",
        "        with open(filename, 'r') as f:\n",
        "          example = f.readline().strip()\n",
        "          target = 1 if polarity == 'pos' else 0\n",
        "          data.append((example, target))\n",
        "    if shuffle:\n",
        "      random.seed(seed)\n",
        "      random.shuffle(data)\n",
        "    X = [pair[0] for pair in data]\n",
        "    y = [pair[1] for pair in data]\n",
        "    return (X, y)\n",
        "  return load('train'), load('test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnNw1TxIcCnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train_text, y_train), (X_test_text, y_test) = load_data('aclImdb/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X14I-ZTXcBBK",
        "colab_type": "text"
      },
      "source": [
        "`X_train_text` et `X_test_text` sont des revues, alors que `y_train` et `y_test` sont leur polarité (`0` pour négatif et `1` pour positif).\n",
        "\n",
        "On vérifie que les données sont bien chargées."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH8ZCHoLNUFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(X_train_text) == 25000\n",
        "assert len(y_train) == 25000\n",
        "assert len(X_test_text) == 25000\n",
        "assert len(y_test) == 25000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PPC3flXdW1Y",
        "colab_type": "text"
      },
      "source": [
        "On peut examiner aléatoirement une revue et sa polarité. (N'hésitez pas à exécuter la cellule plusieurs fois, vous aurez des résultats différents)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN6e4qASVzFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = random.randint(0, len(X_train_text))\n",
        "print(f\"Revue:\\t\\t{X_train_text[idx]}\")\n",
        "print(f\"Polarité:\\t{y_train[idx]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVchUJDbd9fg",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Tokenisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqkIzXaveF50",
        "colab_type": "text"
      },
      "source": [
        "En traitement du langage naturel, on commence (quasiment) toujours par tokeniser les données. Ce qu'un *token* représente dépend de la granularité qu'on cherche. Dans notre TP, on s'intéresse aux mots (*word-level*) plutôt qu'aux caractères (*character-level*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaWRpOO1fxRH",
        "colab_type": "text"
      },
      "source": [
        "Concrètement, on cherche à construire un *vocabulaire* comme ceci\n",
        "```\n",
        "<UNK>: 1\n",
        "hello: 2\n",
        "world: 3\n",
        "```\n",
        "qui associe aux mots un indice entier. Comme  convention, on ajoute un mot fictif `<UNK>` dans notre vocabulaire qui sert à representer tous les mots inconnus.\n",
        "\n",
        "Avec le vocabulaire (de trois mots seulement!!!) ci-dessus, la phrase \n",
        "```\n",
        "my hello word\n",
        "```\n",
        "sera transformée en un vecteur d'entiers\n",
        "```\n",
        "[1, 2, 3]\n",
        "```\n",
        "On rappelle que le mot `my` est inconnu pour ce vocabulaire, et c'est pourquoi il devient `1` (l'indice de `<UNK>`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "379TYMHXhz_l",
        "colab_type": "text"
      },
      "source": [
        "Etant donné un corpus (dans notre cas, le jeu de données IMDB), la taille du vocabulaire est un paramètre à choisir. \n",
        "\n",
        "Si on prend une taille trop petite, on aura des `<UNK>` partout, et il est peu propable que notre modèle apprenne quelque chose. \n",
        "\n",
        "Par contre, si on prend une taille trop grande, notre modèle s'appuyera peut-être sur des mots très rares ce qui n'est pas forcément une bonne chose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbQ6PTl-lTDy",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "En pratique, on prend les $n$ mots les plus fréquents dans le corpus. Et dans le cadre de ce TP, on prend (de façon arbitraire) $n = 6000$. Un bon exercice sera de modifer cette valeur et de regarder l'effet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyidgPzPthym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = 6000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU19ULTllUbD",
        "colab_type": "text"
      },
      "source": [
        "Keras fournit beaucoup d'utilitaires pour pré-processer les textes. En particulier, il existe une classe [Tokenizer](https://keras.io/preprocessing/text/) qui fait toute la tokenisation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI0RXBCXmRj7",
        "colab_type": "text"
      },
      "source": [
        "On initialise un tokeniser en lui indiquant la taille du vocabulaire et le token pour représenter les mots inconnus (*out of vocabulary (oov)*). Ensuite on *fit* le tokeniser sur notre jeu d'entraînement.\n",
        "\n",
        "> A ne pas faire : fit le tokeniser sur le jeu complet (l'union de jeu d'entraînement et le jeu de teste). Pourquoi ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJqpUN0gQHUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=num_words, oov_token='<UNK>')\n",
        "tokenizer.fit_on_texts(X_train_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxZBn4gkm7qJ",
        "colab_type": "text"
      },
      "source": [
        "A l'aide de ce tokeniser, on va pouvoir transformer notre jeux en des vecteurs.\n",
        "\n",
        "A vous de coder !\n",
        "\n",
        "> Indice : utiliser cette fonction [ceci](https://stackoverflow.com/a/55294888)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYAws8FdUb17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train et X_test sont une liste de liste\n",
        "X_train = ### VOTRE CODE ICI ###\n",
        "X_test = ### VOTRE CODE ICI ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGFcm1UXoGUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(X_train) == 25000\n",
        "assert len(X_test) == 25000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FMlXdSUok2v",
        "colab_type": "text"
      },
      "source": [
        "On peut comparer le corpus avant et après tokenisation (n'hésitez pas à exécuter plusieurs fois la cellule)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_A7jjAdtEKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = random.randint(0, len(X_train_text))\n",
        "\n",
        "print(f\"Donnée brute : {X_train_text[idx]}\\n\")\n",
        "print(f\"Après tokenisation : {X_train[idx]}\\n\")\n",
        "print(f\"  Avec des mots: {tokenizer.sequences_to_texts([X_train[idx]])[0]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exQkuYYXs2ZS",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Zero Padding\n",
        "\n",
        "Un dernier détail technique : pour pouvoir entraîner notre réseau en *batch*, il faut que tous les vecteurs dans `X_train` et `X_test` aient la *même longueur*. Pour ce faire, on utilise ce qu'on appelle le \"zero padding\". \n",
        "\n",
        "Concrètement, on se donne une longueur fixe `maxlen`, qui est elle aussi un paramètre à choisir. Si un vecteur dépasse cette longueur, on coupe et ignore le surplus ; si un vecteur est trop court, on le complète avec un token spécial (souvent 0, d'où le nom zero padding) jusqu'à cette longeur.\n",
        "\n",
        "A titre d'exemple, supposons que `maxlen = 4`, alors\n",
        "\n",
        "*   [1, 2, 3, 4, 5] deviendra [1, 2, 3, 4]\n",
        "*   [1, 2] deviendra [1, 2, 0, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-uKsMPyvDsK",
        "colab_type": "text"
      },
      "source": [
        "Pour le reste du TP, on prendra `maxlen = 128`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlvhzvUOvSM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m7gMCXQvTZr",
        "colab_type": "text"
      },
      "source": [
        "Maintenant, on va appliquer le zero padding sur `X_train` et `X_test`.\n",
        "\n",
        "A vous de coder !\n",
        "\n",
        "> Indice : utiliser [cette fonction](https://keras.io/preprocessing/sequence/#pad_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohvBX28luezi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_padded = ### VOTRE CODE ICI ###\n",
        "X_test_padded = ### VOTRE CODE ICI ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2EDlvTvvxBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert X_train_padded.shape == (25000, maxlen)\n",
        "assert X_test_padded.shape == (25000, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H-wucettPeF",
        "colab_type": "text"
      },
      "source": [
        "## Conception du réseau récurrent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4psjyu4VvzcD",
        "colab_type": "text"
      },
      "source": [
        "Il est enfin temps de construire notre réseau ! Pour attaquer ce type de problème, il est courant d'utiliser un réseau de neurones récurrent (RNN). En pratique, on utilise très rarement le RNN de base à cause du problème de [vanishing gradient](https://en.wikipedia.org/wiki/Vanishing_gradient_problem). \n",
        "\n",
        "Dans ce TP, on utilise une variante qui s'appelle LSTM (Long-Short Term Memory)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGWoWWrby9gk",
        "colab_type": "text"
      },
      "source": [
        "Notre réseau ressemble au schéma suivant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6eCtCRByrt6",
        "colab_type": "text"
      },
      "source": [
        "![Texte alternatif…](https://cdn-images-1.medium.com/max/1000/1*SICYykT7ybua1gVJDNlajw.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfhOnSIhzCiQ",
        "colab_type": "text"
      },
      "source": [
        "En Keras, la construction d'un tel réseau est très simple : il suffit de définir un modèle séquentiel et d'y ajouter couche par couche les blocs suivants\n",
        "\n",
        "1.   [Embedding](https://keras.io/layers/embeddings/) avec `output_dim = 128`. Fixez la valeur de `input_dim`, et laissez les autres paramètres par défaut.\n",
        "2.   [LSTM](https://keras.io/layers/recurrent/#lstm), avec `units = 32`. Laissez les autres paramètres par défaut.\n",
        "3.   [Dense](https://keras.io/layers/core/), avec `units = 1` et `activation = 'sigmoid'`. Laissez les autres paramètres par défaut.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf8M8aqmtaFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(### VOTRE CODE ICI ###)\n",
        "model.add(### VOTRE CODE ICI ###)\n",
        "model.add(### VOTRE CODE ICI ###)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1j9BGIh08E7",
        "colab_type": "text"
      },
      "source": [
        "En Keras, un modèle doit être compilé avant de pouvoir être utilisé. C'est aussi le moment de préciser la fonction de coût, l'optimiseur ainsi que la métrique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7jI2Wek1P0R",
        "colab_type": "text"
      },
      "source": [
        "Compilez le modèle, à l'aide de [`model.compile()`](https://keras.io/models/sequential/#compile) avec les paramètres ci-dessous\n",
        "\n",
        "*   loss = 'binary_crossentropy'\n",
        "*   optimizer = 'adam'\n",
        "*   metrics = ['accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBk6fmJq0xI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(### VOTRE CODE ICI ###)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjCMLPS61sM3",
        "colab_type": "text"
      },
      "source": [
        "On peut visualiser notre modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6B0k5now8hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_model(model, \"model.png\")\n",
        "Image(\"model.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7z7chzl147Q",
        "colab_type": "text"
      },
      "source": [
        "Enfin, si on veut avoir plus de détails sur le réseau, par exemple la dimension ainsi que le nombre de paramètres de chaque couche, on peut utiliser la fonction `model.summary()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8na26DMtnxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M_9jwlRtriF",
        "colab_type": "text"
      },
      "source": [
        "### Entraînement du réseau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0hUbehf2WEW",
        "colab_type": "text"
      },
      "source": [
        "Une fois le réseau compilé, l'entraînement est simple comme bonjour."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppkhVahD2kX2",
        "colab_type": "text"
      },
      "source": [
        "Entraînez le modèle sur `X_train_padded` et `y_train`, à l'aide de la fonction [`model.fit()`](https://keras.io/models/sequential/#fit), avec les paramètres suivants\n",
        "*   batch_size = 128\n",
        "*   epochs = 5\n",
        "*   validation_split = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO--RSgBtq-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(### VOTRE CODE ICI ###)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCMhNAC56t7m",
        "colab_type": "text"
      },
      "source": [
        "Il est souvent très utile de tracer l'accuracy et la loss le long de l'entraînement. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cSNix6KwZHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjAF6T5tykW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq6DCdxrwZh4",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation du réseau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQNAkdqf6_0H",
        "colab_type": "text"
      },
      "source": [
        "Pour évaluer un modèle de machine learning, l'approche canonique est de le tester sur un jeu de données, en l'occurrence, `X_test_padded`, que l'on a pas touché (du tout !) pendant l'entraînement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIvRJ8bS7Z40",
        "colab_type": "text"
      },
      "source": [
        "A vos de coder !\n",
        "\n",
        "> Indice : utilisez [cette fonction](https://keras.io/models/sequential/#evaluate). Pensez à augmenter `batch_size` (par défaut c'est 1), 128 est une valeur souvent utilisée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJJz3sSFv26A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, accuracy = model.evaluate(### VOTRE CODE ICI ###)\n",
        "print(f\"loss: {loss}\")\n",
        "print(f\"accuracy: {accuracy}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5Ay2Br17zMu",
        "colab_type": "text"
      },
      "source": [
        "## Testez avec vos exemples !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-kKIliK76i-",
        "colab_type": "text"
      },
      "source": [
        "Tester sur le jeu de test, c'est amusant. C'est encore plus intéressant si on teste sur notre propre \"revue\" !\n",
        "\n",
        "Cette fois-ci, on a codé pour vous :) Jouez avec la fonction `predict` suivante !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy32l2tv75_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(sentence):\n",
        "  sequences = tokenizer.texts_to_sequences([sentence])\n",
        "  sequences_padded = pad_sequences(sequences, maxlen=maxlen)\n",
        "  y_pred = model.predict(sequences_padded)\n",
        "  y_pred = np.squeeze(y_pred)\n",
        "  return \"positive\" if y_pred >= 0.5 else \"negative\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LlkDj709TE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(\"I really loved this film, it was fantastic!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw38Jfca8KGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(\"I don't understand how anyone can be optimistic about this film.\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}